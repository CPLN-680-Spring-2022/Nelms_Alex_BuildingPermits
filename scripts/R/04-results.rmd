
In this section, I create a basic Ordinary Least Squares linear regression to underestand the relationship between New Housing Units (2015-19) and various predictor variables. 

I will be performing a 75% split.

```{r setup_train_test_partition}

var.dv = "units.tot.15_19"
var.ivs = c(vars.ivs.disc_fin, vars.ivs.cont_fin)
var.ivs = var.ivs[!(var.ivs %in% remove_col)]

select_v = function(sf, variable_names=c(var.dv, var.ivs)){
  return(sf %>% st_drop_geometry(.) %>%
             select(variable_names))}

select_iv = function(sf, variable_names=var.ivs){
  return(sf %>% st_drop_geometry(.) %>%
             select(variable_names))}

inTrain = createDataPartition(
              y = sf.predict %>% pull(units.tot.15_19), 
              p = .75, list = FALSE)

sf.train = 
  sf.predict[inTrain,] %>% 
  select(c(vars.admin, var.dv, var.ivs))

sf.test = 
  sf.predict[-inTrain,] %>% 
  select(c(vars.admin, var.dv, var.ivs))

```


With a training set, the study can now build its initial training linear model [lm.train] based on the predictor variables constructed in Section 2


```{r setup_train_lm}

#var.ivs = var.ivs %>% list()
var.dv = var.dv

var.ivs.str = 
  do.call(paste, c(var.ivs %>% list(), collapse = "+"))

fm_equation = as.formula(paste(
  var.dv, var.ivs.str, sep="~"))

print(fm_equation)


lm.train = 
  lm(
    fm_equation, 
    data = sf.train %>% select_v(.)
    )
```


The results of our model on the training set are presented below. The results highlight that there is a mixed bag of predictors being significant.

``` {r table_train_summ, results = "asis"}
tab_num = 3

format_nums = function(num_input, digits = 2) ifelse(abs(num_input)>999,
                      count_format(num_input),
                      round_thresh(num_input, digits = digits,int_check = TRUE))

lm.train.summ = 
  lm.train %>%
  tidy() %>%
  transmute(
    Variable = 
      term, 
    Estimate = format_nums(estimate, digits = 3),  #%>%
      #paste('$', .),
    std.error = format_nums(std.error), # %>%
      #paste('$', .),
    t.value = format_nums(statistic),
    p.value = p.value %>% round_thresh()
  )

lm.train.summ %>%
  kable(
    label = NA,
    caption = glue('Table {tab_num}: Training Model Summary'),
    align = 'lrrrr') %>%
  kable_styling()
```

Table 3 shows that the most significant variables are Building Area that is residential (bsqft_res.pct.2019), the count of permits (permits.tot.15_19), the change in percent that's white (wht.pct.10_15), the change in median income  from 2000 to 2018 (minc_ch.pct.00_18), the median home value in 1990 (hval.med.90), and the change in percent that is owner occupied (occ_own_ch.pct.00_18). This is very interesting findings as it suggests that **areas with more added housing also have higher changes in income, percent of renters, home values, and the percent of white people**. 

``` {r table_train_err, results = "asis"}

tab_num = 4

title = glue('Table {tab_num}: Training Model Fit & Significance Terms')

lm.train %>% glance() %>%
  transmute(
    `RSE` = format_nums(sigma), #%>%
      #paste('$', .),
    `df ` = format_nums(df.residual),
    `Multiple` = format_nums(r.squared, digits=4),
    `Adjusted` = format_nums(adj.r.squared, digits=4),
    `stat` = format_nums(statistic, digits=1),,
    `df` = format_nums(df),
    p.value = p.value %>% round_thresh()
  ) %>%
  kable(
    label = NA,
    caption = title,
    align = 'lrrrr') %>%
  kable_styling() %>%
  add_header_above(
    header = c(
      'Residual Standard Error'=2,
      'R-squared' = 2,
      'F-statistic' = 2,
      ' ' = 1
    ))
```
Table 4 also highlights that the R-Squared is fairly high at .85 -- suggesting that our model has a vairly solid predicting power. 

###  Errors

Figure 5 shows the different errors of the model. The plots suggest that a small section of the block groups have extremely high errors while others are fairly normal. The graphs suggest that block groups with very little added units have the highest errors. This could be due to some block groups having a smaller population of housing units and people. It could also be that those block groups have similar demographics and characteristics to those of high units added . . . but don't have any units being added. 


```{r setup_all_predict, include=FALSE}

sf.predict = 
  rbind(
    sf.predict[, colnames(sf.predict)],
    sf.predict
  ) %>%
  mutate(
    regression      = "Final Regression",
    units1519.predict   = predict(lm.train, .),
    
    # Residual
    units1519.error     = units.tot.15_19 - units1519.predict, 
    units1519.abserror = abs(units1519.predict - units.tot.15_19), 
    units1519.pe      = (units1519.error / ifelse(units.tot.15_19==0, 0.1, units.tot.15_19)),
    units1519.ape      = (units1519.abserror / ifelse(units.tot.15_19==0, 0.1, units.tot.15_19)),
    
    units1519.rmse  = sqrt(mean((units1519.error)^2, na.rm=TRUE))
  )%>% 
  filter(units1519.ape<7000)

# sf.predict %>%
#   st_drop_geometry() %>%
#   mutate(units1519.predict = predict(train.cv, .)) %>%
#   select(id.musa, units1519.predict) %>% 
#   arrange(id.musa) %>%
#   rename(
#     MUSA_ID = id.musa,price = units1519.predict
#   ) %>%
#   write.csv("Nelms-Mangiapane.csv")

```
```{r plot_train_lm}

fig_num = 5

title = glue('Figure {fig_num}: Observed Added Units & Test Error')

m = 1000000

# get lm of Absolute Error & Price
geom_vline_lim = function(xintercept=1, ylim=c(1,Inf), ...) geom_line(data = data.frame(x = c(xintercept, xintercept), y = ylim), aes(x = x , y = y), ...)

# two means of ME
ME_2 = sf.predict %>%
  pull(units1519.error) %>%
  mean(., na.rm = T)

ME_1 = sf.predict %>%
  pull(units1519.error) %>%
  mean(., na.rm = T)

MAE_lm_fit <- lm(units.tot.15_19 ~ units1519.abserror, data=sf.predict)
summary(MAE_lm_fit)

ape_breaks = c(0,1,2.5,5)
pe_breaks = c(-5,-2.5,-1,0,1)

xmoney_breaks = c(0,1,2,4,6) * m
negxmoney_breaks = c(-2,-1,0,1,2,4) * m
ymoney_breaks = c(0,1,2,4,6) * m

percent_formatter = function(str) (str * 100) %>% round() %>% format(., big.mark = ",") %>% paste0(., "%")


grid.arrange(ncol=2,
  ggplot(data = sf.predict) +
    geom_point(aes(y = units.tot.15_19, x = units1519.error)) +
    # scale_x_continuous(breaks = negxmoney_breaks,
    #                    labels = money_format,
    #                    name = 'Price - Predicted Price') +
    # scale_y_continuous(breaks = ymoney_breaks, labels = money_format) +
    # geom_vline_lim(xintercept=ME_1, ylim=c(0,2*m), color='#90ee90', size=1.25, linetype = "solid") + 
    #     geom_vline_lim(xintercept=ME_2, 
    #                    ylim=c(2*m,8*m), 
    #                    color='#BF40BF', size=1.25, linetype = "solid") + 
    # #geom_vline(xintercept = test.ME, colour="#90ee90", size=1, linetype = "longdash") + 
    labs(title=title, subtitle = 
           glue("Error (ME = {sf.predict %>% pull(units1519.error) %>% mean(.) %>% round()})")) +
    plotTheme(),

  ggplot(data = sf.predict) +
    geom_point(aes(y = units.tot.15_19, x = units1519.pe)) +
    # scale_x_continuous(breaks = pe_breaks, name = 'Error / Price',
    #             labels = percent_formatter(pe_breaks)) + 
    # scale_y_continuous(breaks = ymoney_breaks, labels = money_format) + 
    # geom_vline(xintercept = test.MPE, colour="#FF9B00", size=1, linetype = "longdash") + 
    # 
    # geom_vline(xintercept = test.MPE, colour="#FF9B00", size=1, linetype = "longdash") + 
    # 
    labs(title='', subtitle = 
           glue("Percent Error (MPE = {percent_formatter(sf.predict %>% pull(units1519.pe) %>% mean(.) )})")) +
    plotTheme(),
  
  ggplot(data = sf.predict) +
    geom_point(aes(y = units.tot.15_19, x = units1519.abserror)) +
    # scale_x_continuous(breaks = xmoney_breaks,
    #                    labels = money_format,
    #                    name = 'Absolute Error') + 
    # scale_y_continuous(breaks = ymoney_breaks, labels = money_format) + 
    # geom_line(color='red',data = 
    #         data.frame(MAE_fit = predict(MAE_lm_fit, sf.test), 
    #                    hp=sf.test$units1519.abserror), aes(x=hp, y=MAE_fit)) + 
    # geom_vline(xintercept = test.MAE, colour="#50c878", size=1, linetype = "longdash") + 
    labs(subtitle = 
           glue("Absolute Error (MAE = {sf.predict %>% pull(units1519.abserror) %>% mean(.)  %>% round()})")) +
    plotTheme(),
  
  ggplot(data = sf.predict ) +
    geom_point(aes(y = units.tot.15_19, x = units1519.ape)) +
    # scale_x_continuous(breaks = ape_breaks, name = 'Absolute Percentage Error',
    #            labels = percent_formatter(ape_breaks)) + 
    # scale_y_continuous(breaks = ymoney_breaks, labels = money_format) + 
    # geom_vline(xintercept = test.MAPE, colour="#ff8c00", size=1, linetype = "longdash") + 
    labs(subtitle = 
           glue("Absolute Percent Error (MAPE = {sf.predict %>% pull(units1519.ape) %>% mean(.)  %>% round()})")) + 
    plotTheme()
)

```


###  Scatterplot
*Plot predicted prices as a function of observed prices*

Figure 6 highlights the trends seen in the Test Errors Scatterplot (Figure 5). There are predictions of negative added housing. Which is very strange. It suggests that the model is assuming some blocks should have less added housing units. It also appears that there was an over prediction for some of the same blocks that have no housing units. 

``` {r plot_all_predict_real}

fig_num = 6
title = glue('Figure {fig_num}: Predicted & Observed Sales Prices')

line_min = min(max(sf.predict$units.tot.15_19), max(sf.predict$units1519.predict))

ggplot() +
    geom_point(data = sf.predict, aes(x = units.tot.15_19, y = units1519.predict)) +
    geom_smooth(data = sf.predict, aes(x = units.tot.15_19, y = units1519.predict), method = lm, color='green') + 
    # geom_line(data=data.frame(
    #       x=c(0,line_min+1*m),
    #       y=c(0,line_min+1*m)),
    #       aes(x=x,y =y), linetype='dashed',
    #               size=1.25, color='orange') +
    # scale_x_continuous(breaks = c(0,1,1.5,2.5,5)*m,
    #                    #labels = money_format,
    #                    name = 'Observed Price') +
    # scale_y_continuous(breaks = c(0,1,1.5,2.5)*m, name = 'Predicted Price',) +
    labs(title=title,
      subtitle = "Final Predicted Housing Prices") +
    #xlim(min(sf.predict$price,0), max(sf.predict$price)) + 
    #ylim(min(sf.predict$units1519.predict,0), max(sf.predict$units1519.predict)) + 
    plotTheme()

```

### Errors Map

The errors map helps locate where there is incorrect predictions. Based on the absolute percentage error, the area just above the tenderloin & downtown in the Northeastern area is the highest. This area of Chinatown & North Beach likely defies the argument that areas of high renters and/or lower-income residents are where development is happening. The Chinatown area has been resistant to development and has minimized the amount of displacement -- typically seen by low-income, long-term residents of the Tenderloin & Mission. The North Beach area has higher amounts of higher-income, younger renters -- but not that much development. Likely from the very steep hills.

``` {r map_predictions}

map_num = 4

Var1_map = 
  ggplot() +
    geom_sf(data=sf.predict, aes(fill=units1519.error))+ 
  scale_fill_distiller(palette = "RdYlGn", direction = 1) +
  ggtitle("Error") + 
  mapTheme()

Var2_map = 
  ggplot() +
    geom_sf(data=sf.predict, aes(fill=units1519.ape))+ 
  scale_fill_distiller(palette = "Reds", direction = 1) +
  ggtitle("Abosolute Percentage Error") + 
  mapTheme()

title = glue('Map {map_num}: Home Value Predictions\nFinal Model on Full Dataset')
grid.arrange(
  Var1_map,
  Var2_map,
  #Var3_map,
  #Var4_map,
  ncol=2,
  top = grid::textGrob(title,gp=grid::gpar(fontsize=15))
)

```
   
## Conclusion

The linear model was more of a success than I could have predicted *(no pun intended)*. The model's significant predictors shows signs that new housing is added in areas where there *is* a large amount of demographic and income changes. 
