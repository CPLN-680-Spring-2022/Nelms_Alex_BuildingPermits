{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Packages, Dates, & Initials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'C:\\Users\\nelms\\Documents\\Penn\\CPLN-680\\Permit_Metrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "#from labellines import labelLine, labelLines\n",
    "\n",
    "#administrative packages\n",
    "import os\n",
    "import datetime\n",
    "mydate = datetime.datetime.now()\n",
    "from datetime import date,timedelta\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "#standard packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#from labellines import labelLine, labelLines\n",
    "\n",
    "#administrative packages\n",
    "import os\n",
    "import operator\n",
    "import datetime\n",
    "mydate = datetime.datetime.now()\n",
    "from datetime import date,timedelta\n",
    "import time\n",
    "start = time.time()\n",
    "import logging\n",
    "logger = logging.getLogger('ftpuploader')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Zoning Amendment': 'Amend',\n",
       " 'Use Permit Minor': 'MUP',\n",
       " 'Design Review': 'DR',\n",
       " 'Design Review Oversized Home': 'DR',\n",
       " 'Design Review Other': 'DR',\n",
       " 'Design Review Commercial': 'DR',\n",
       " 'General Plan Amendment': 'Amend',\n",
       " 'Design Review Antenna': 'DR',\n",
       " 'Design Review Residential': 'DR',\n",
       " 'Use Permit Conditional': 'CUP',\n",
       " 'Use Permit Administrative': 'AUP',\n",
       " 'ZCL': 'ZCL',\n",
       " 'Variance': 'Vari',\n",
       " 'Rezoning': 'ReZone',\n",
       " 'Tree Dripline Encroachment': 'Tree',\n",
       " 'Tree Removal Permit': 'Tree',\n",
       " 'Other': 'Other',\n",
       " 'Tentative Map Major Subdivision': 'Maj Sub',\n",
       " 'Drip Line Encroachment': 'Other',\n",
       " 'Tentative Map Minor Subdivision': 'Min Sub',\n",
       " 'Tentative Map Condo Conversion': 'Conv',\n",
       " 'Hillside Performance Standards': 'Other'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.get_holidays import get_holidays\n",
    "holidays = get_holidays()\n",
    "\n",
    "from scripts.get_planners import get_planners\n",
    "planners = get_planners('WC')\n",
    "\n",
    "from scripts.get_entitlement_types import get_entitlement_types\n",
    "entitlements = get_entitlement_types('WC')\n",
    "\n",
    "from scripts.get_taskstatus_dict import *\n",
    "TaskStatus = get_taskstatus_dict(['WC', 'Planning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T18:31:50.501905Z",
     "start_time": "2021-04-23T18:31:50.476908Z"
    },
    "code_folding": [
     102,
     126,
     154,
     163
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Status - Received': 'Start',\n",
       " 'Intake Review - Application Accepted': 'Start',\n",
       " 'Consolidated Comments - Deemed Incomplete': 'Round_End',\n",
       " 'Resubmittal - Route for Review': 'Round_Start',\n",
       " 'Consolidated Comments - Deemed Complete': 'End',\n",
       " 'Close Out - Approved': 'End',\n",
       " 'Staff Analysis - Set for Hearing': 'End',\n",
       " 'Staff Analysis - Staff Level Decision': 'End',\n",
       " 'Close Out - Not Approved - Closed': 'End'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TaskStatus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T18:31:50.764872Z",
     "start_time": "2021-04-23T18:31:50.501905Z"
    },
    "code_folding": [
     22
    ]
   },
   "outputs": [],
   "source": [
    "accela_directory = r'O:\\CDD\\PLANNING\\AN\\Projects\\Accela Reporting\\Combined'\n",
    "dept_paths = {\n",
    "    'Planning':'PermitMetrics_Planning.csv',\n",
    "    'Building':'PermitMetrics_Building.csv',\n",
    "    'Site Development Permit':'PermitMetrics_SDP.csv'\n",
    "          }\n",
    "def combine_dept_permits(path_dictionary, directory_path):\n",
    "    os.chdir(directory_path)\n",
    "    \n",
    "    PLAN = pd.read_csv(path_dictionary['Planning'])\n",
    "    lu = ['Residential', 'Commercial']\n",
    "    PLAN['Permit Type'].fillna(value='', inplace=True)\n",
    "    PLAN['Type of Work'] = PLAN['Permit Type'].apply(lambda s: [s for s in s.split(' ') if s in lu][0] if any(l in s for l in lu) else '')\n",
    "    PLAN['Record Type'] = 'Planning'\n",
    "    \n",
    "    SDP = pd.read_csv(path_dictionary['Site Development Permit'])\n",
    "    SDP['Type of Work'] = SDP['Permit Type'].apply(lambda s: 'Commercial' if s == 'COMM' else s)\n",
    "    SDP.loc[SDP['Type of Work']=='Subdivision', 'Type of Work'] = 'Residential'\n",
    "    SDP['Type of Work'].unique()\n",
    "\n",
    "    BUILD = pd.read_csv(path_dictionary['Building'])\n",
    "    BUILD.drop(columns='Construction Type', inplace=True)  #['Permit Type'] = BUILD['Construction Type'].apply(lambda x: const_dict[x]['subtype'] if x>0 else '')\n",
    "    const_dict = {\n",
    "     101: {'type of work': 'Residential',\n",
    "      'subtype': 'Construction',\n",
    "      'definition': 'Single Family Houses - Detached'},\n",
    "     102: {'type of work': 'Residential',\n",
    "      'subtype': 'Construction',\n",
    "      'definition': 'Single Family Houses - Attached'},\n",
    "     103: {'type of work': 'Residential',\n",
    "      'subtype': 'Construction',\n",
    "      'definition': 'Two Family Buildings'},\n",
    "     104: {'type of work': 'Residential',\n",
    "      'subtype': 'Construction',\n",
    "      'definition': 'Three and Four Family Buildings'},\n",
    "     105: {'type of work': 'Residential',\n",
    "      'subtype': 'Construction',\n",
    "      'definition': 'Five or More Family Buildings'},\n",
    "     106: {'type of work': 'Residential',\n",
    "      'subtype': 'Construction',\n",
    "      'definition': 'ADU (New Detached, Additions & Conversrion)'},\n",
    "     109: {'type of work': 'Residential',\n",
    "      'subtype': 'Construction',\n",
    "      'definition': 'Other (Including Residential Foundation only permit)  '},\n",
    "     213: {'type of work': 'Commercial',\n",
    "      'subtype': 'Construction',\n",
    "      'definition': 'Hotels, Motels, and Tourist Cabins'},\n",
    "     214: {'type of work': 'Commercial',\n",
    "      'subtype': 'Construction',\n",
    "      'definition': 'Other No Housekeeping Shelter'},\n",
    "     318: {'type of work': 'Commercial',\n",
    "      'subtype': 'Construction',\n",
    "      'definition': 'Amusement, Social, and Recreational'},\n",
    "     319: {'type of work': 'Commercial',\n",
    "      'subtype': 'Construction',\n",
    "      'definition': 'Churches and Other Religeous Buildings'},\n",
    "     320: {'type of work': 'Commercial',\n",
    "      'subtype': 'Construction',\n",
    "      'definition': 'Industrial Buildings'},\n",
    "     321: {'type of work': 'Commercial',\n",
    "      'subtype': 'Construction',\n",
    "      'definition': 'Parking Garages (Buildings & Open Decked)'},\n",
    "     322: {'type of work': 'Commercial',\n",
    "      'subtype': 'Construction',\n",
    "      'definition': 'Service Stations and Repair Garages'},\n",
    "     323: {'type of work': 'Commercial',\n",
    "      'subtype': 'Construction',\n",
    "      'definition': 'Hospitals and Institutional Buildings'},\n",
    "     324: {'type of work': 'Commercial',\n",
    "      'subtype': 'Construction',\n",
    "      'definition': 'Office, Bank, and Professional Buildings'},\n",
    "     325: {'type of work': 'Commercial',\n",
    "      'subtype': 'Construction',\n",
    "      'definition': 'Public Works and Utilities Buildings'},\n",
    "     326: {'type of work': 'Commercial',\n",
    "      'subtype': '',\n",
    "      'definition': 'Schools and Other Educational Buildings'},\n",
    "     327: {'type of work': 'Commercial',\n",
    "      'subtype': 'Construction',\n",
    "      'definition': 'Stores and Customer Service'},\n",
    "     328: {'type of work': 'Commercial',\n",
    "      'subtype': 'Construction',\n",
    "      'definition': 'Other Nonresidential Buildings (Including foundation only permit)'},\n",
    "     329: {'type of work': 'Commercial',\n",
    "      'subtype': 'Construction',\n",
    "      'definition': 'Structures Other Than Buildings'},\n",
    "     434: {'type of work': 'Commercial',\n",
    "      'subtype': 'Additions',\n",
    "      'definition': 'Additions, Alterations and Conversions - Residential (Includes A.D.U.)'},\n",
    "     437: {'type of work': 'Commercial',\n",
    "      'subtype': 'Additions',\n",
    "      'definition': 'Additions, Alterations and Conversions - Nonresidential and No Housekeeping'},\n",
    "     438: {'type of work': 'Residential',\n",
    "      'subtype': 'Additions',\n",
    "      'definition': 'Additions of Residential Garages and Carports'},\n",
    "     645: {'type of work': 'Residential',\n",
    "      'subtype': 'DEMO',\n",
    "      'definition': 'DEMO Single Family Houses'},\n",
    "     646: {'type of work': 'Residential',\n",
    "      'subtype': 'DEMO',\n",
    "      'definition': 'DEMO Two Family Buildings'},\n",
    "     647: {'type of work': 'Residential',\n",
    "      'subtype': 'DEMO',\n",
    "      'definition': 'DEMO Three and Four Family Buildings'},\n",
    "     648: {'type of work': 'Residential',\n",
    "      'subtype': 'DEMO',\n",
    "      'definition': 'DEMO Five or More Family Buildings'},\n",
    "     649: {'type of work': 'Commercial',\n",
    "      'subtype': 'DEMO',\n",
    "      'definition': 'DEMO All Other Buildings and Structures'}\n",
    "    }\n",
    "    \n",
    "    p_cols = [c for c in list(PLAN) if c not in set(list(BUILD)+list(SDP))]\n",
    "    p_not_cols = [c for c in set(list(BUILD)+list(SDP)) if c not in list(PLAN)]\n",
    "    if len(p_cols+p_not_cols) > 0:\n",
    "        print(\"Planning cols that are not in the rest: \", p_cols)\n",
    "        print(\"Planning cols that are missing from the rest: \", p_not_cols)\n",
    "    \n",
    "    b_cols = [c for c in list(BUILD) if c not in set(list(PLAN)+list(SDP))]\n",
    "    b_not_cols = [c for c in set(list(PLAN)+list(SDP)) if c not in list(BUILD)]\n",
    "    if len(b_cols+b_not_cols) > 0:\n",
    "        print(\"Building cols that are not in the rest: \", b_cols)\n",
    "        print(\"Building cols that are missing from the rest: \", b_not_cols)\n",
    "        \n",
    "    s_cols = [c for c in list(SDP) if c not in set(list(BUILD)+list(PLAN))]\n",
    "    s_not_cols = [c for c in set(list(BUILD)+list(PLAN)) if c not in list(SDP)]\n",
    "    if len(s_cols+s_not_cols) > 0:\n",
    "        print(\"SDP cols that are not in the rest: \", s_cols)\n",
    "        print(\"SDP cols that are missing from the rest: \", s_not_cols)\n",
    "\n",
    "    All_Depts = pd.concat([PLAN, SDP, BUILD])\n",
    "    Extra_Types = [d for d in All_Depts['Record Type'].unique() if d not in dept_paths.keys()]\n",
    "    if len(Extra_Types)>0:\n",
    "        print(Extra_Types)\n",
    "    \n",
    "    All_Depts['Address'].fillna(value='')\n",
    "    All_Depts['Address'] = All_Depts['Address'].apply(\n",
    "        lambda a: ' '.join([\n",
    "            aa.capitalize() for aa in a.split(', ')[0].split(' ')\n",
    "        ]) if type(a)==str else str(a)\n",
    "    )\n",
    "    \n",
    "    All_Depts.loc[All_Depts['Type of Work']=='RES', 'Type of Work'] = 'Residential'\n",
    "    \n",
    "    return All_Depts\n",
    "\n",
    "Permits = combine_dept_permits(dept_paths, accela_directory)\n",
    "\n",
    "P = Permits.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Format Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T18:32:01.335083Z",
     "start_time": "2021-04-23T18:31:50.764872Z"
    },
    "code_folding": [
     2,
     50
    ]
   },
   "outputs": [],
   "source": [
    "Permits = P.copy()\n",
    "\n",
    "Record_cols = [\n",
    "        'Permit #',\n",
    "        #'Task Status',\n",
    "        'Round Status',\n",
    "        'Date Assigned',\n",
    "        'Date Status',\n",
    "        'Updated Date'\n",
    "              ]\n",
    "Admin_cols = ['Permit #',\n",
    "             'Record Type',\n",
    "             'Type of Work',\n",
    "             'Permit Type',\n",
    "             'Record Status',\n",
    "             'Open Date',\n",
    "             'Description',\n",
    "             'APN',\n",
    "             'Address'\n",
    "             ]\n",
    "\n",
    "def format_data(P_df):\n",
    "    \n",
    "    # turns date columns into datetime format\n",
    "    date_cols = [col for col in list(P_df) if ('Date ' in col)or(' Date' in col)]\n",
    "    P_df[date_cols] = P_df[date_cols].apply(pd.to_datetime)\n",
    "    \n",
    "    # Column identifying the record's workflow position through the completed task\n",
    "    P_df['Task Status'] = P_df['Task'] + ' - ' + P_df['Status']\n",
    "    \n",
    "    # Column identifying the record's round position\n",
    "    # non-NaN records are tasks that end or start a round through accepting or denying a submitted application\n",
    "    P_df['Round Status'] = P_df['Task Status']\n",
    "    \n",
    "    # By looping by department/permit type, the script can apply nested, translated dictionaries \n",
    "    # The TaskStatus dictionary translates the task statuses into the round statuses\n",
    "    # If the TaskStatus isn't in the department's nested dictionary, it receives an NaN\n",
    "    for dept in P_df['Record Type'].unique():\n",
    "        P_df.loc[P_df['Record Type']==dept, 'Round Status'] = P_df.loc[P_df['Record Type']==dept, 'Round Status'].map(TaskStatus[dept])\n",
    "    \n",
    "    # This filters out the NaN records that did not give a round status\n",
    "    #P_df = P_df.loc[~P_df['Round Status'].isna()].copy()\n",
    "    \n",
    "    # Removes the duplicates\n",
    "    P_df.drop_duplicates(subset=['Task Status']+Record_cols, inplace=True)\n",
    "    \n",
    "    return P_df\n",
    "\n",
    "Permits = format_data(Permits)\n",
    "\n",
    "def Planning_Formats(Plan_df):\n",
    "    raw_records = Plan_df.set_index('Permit #')\n",
    "\n",
    "    # For Planning Applications, allow received date\n",
    "    if 'Status - Received' in temp.index.get_level_values(1):\n",
    "\n",
    "        temp.reset_index(inplace=True)\n",
    "        focus = set(temp[temp['Task Status'].isin(['Status - Assigned', 'Status - Received'])].index)\n",
    "        #IDs = {i:[] for i in focus}\n",
    "        #[IDs[i].append(ts) for i in focus]\n",
    "        #IDs = [k for k,v in IDs.items() if len(v) > 1]\n",
    "        for x in focus:\n",
    "            temp.loc[x, 'DATE ASSIGNED'] = temp.loc[x, 'DATE STATUS']\n",
    "            temp.loc[x, 'DATE STATUS'] = temp.loc[x, 'UPDATED DATE']\n",
    "        temp.set_index(['Permit #', 'Task Status'], inplace=True)\n",
    "    \n",
    "    Plan_Review = raw_records.loc[(raw_records['INTAKER'] != ' '), 'INTAKER'].map(planner_names)\n",
    "\n",
    "    Assigned = raw_records[raw_records['Task Status']=='Planning Review - Assigned - Notify Applicant'].copy()\n",
    "    Assigned['INTAKER'] = Assigned['INTAKER'].map(planner_names)\n",
    "    Assigned = Assigned['INTAKER'].to_dict()\n",
    "\n",
    "    # Determine project planner\n",
    "    ## Typically most common planner on project\n",
    "    def find_planner(series):\n",
    "        planner_counts = series.value_counts().sort_values(ascending=True).to_dict()\n",
    "\n",
    "        planner_list = [plnr for plnr, v in sorted(planner_counts.items(), key=lambda item: item[1], reverse=True) \n",
    "                        if (plnr in planner_initials.keys()) and (plnr not in ['GV', 'AS']) and (type(plnr)==str)]\n",
    "        if len(planner_list) == 0:\n",
    "            update_planner = 'GV'\n",
    "        else:\n",
    "            update_planner = planner_list[0]\n",
    "        try:\n",
    "            return update_planner\n",
    "        except:\n",
    "            print(planner_counts, planner_list)\n",
    "            return ''\n",
    "\n",
    "    Plan_prep = raw_records['INTAKER'].map(planner_names)\n",
    "\n",
    "    raw_records = raw_records.drop(columns='INTAKER')\n",
    "\n",
    "    Plan_prep = pd.concat((Plan_prep, Plan_Review))\n",
    "    Plan_prep.name = 'INTAKER'\n",
    "\n",
    "    Plan_prep = pd.DataFrame(Plan_prep).reset_index()\n",
    "\n",
    "    Plan_prep = Plan_prep[~Plan_prep['INTAKER'].isna()]\n",
    "\n",
    "    Planners = Plan_prep.groupby('Permit #').agg(INTAKER=('INTAKER',find_planner))\n",
    "\n",
    "    raw_records = raw_records.join(Planners)\n",
    "\n",
    "    raw_records = raw_records.reset_index().drop_duplicates()\n",
    "\n",
    "    raw_records.loc[raw_records['Permit #'].isin(Assigned.keys()),'INTAKER'] = raw_records.loc[raw_records['Permit #'].isin(Assigned.keys()),'Permit #'].map(Assigned)\n",
    "\n",
    "    def straight_record(name):\n",
    "        name = str(name).title().strip()\n",
    "        name = name.replace(\"'S\", \"'s\").replace(\"Sfr\", \"SFR\").replace(\" Wc \", \" WC \").replace(\"Zcl\",\"ZCL\").replace(\"Aup\",\"AUP\").replace(\"Cup\",\"CUP\")\n",
    "        if len(name) > 30:\n",
    "            for a in ['@', ' At ', '&', ' And ']:\n",
    "                if a in name:\n",
    "                    name = name.split(a)[0].strip()\n",
    "        if len(name) > 40:\n",
    "            for a in ['&', ' And ']:\n",
    "                if a in name:\n",
    "                    name = name.split(a)[0].strip()\n",
    "        if len(name) > 45:\n",
    "            name = ' '.join(name.split(' ')[:7])\n",
    "        return name\n",
    "\n",
    "    raw_records['Name'] = raw_records['RECORD NAME'].apply(lambda a: straight_record(a))\n",
    "\n",
    "    raw_fields.extend(['Name','INTAKER'])\n",
    "    \n",
    "    return raw_fields\n",
    "\n",
    "pts = [' '.join([i,ts,str(d),str(dd),str(ddd)]) for i,ts,d,dd,ddd in Permits[['Permit #', 'Task Status', 'Date Assigned', 'Date Status', 'Updated Date']].values]\n",
    "\n",
    "print(len(set(pts)))\n",
    "print(len(pts))\n",
    "\n",
    "Admin = Permits[Admin_cols].copy().drop_duplicates().set_index('Permit #')\n",
    "\n",
    "Records = Permits[Record_cols].sort_values(['Permit #']+sorts).set_index(['Permit #', 'Round Status'])\n",
    "\n",
    "Records['Index'] = 0\n",
    "def indexer(R_df):\n",
    "    R_df.sort_values(by=sorts, inplace=True)\n",
    "    R_df.reset_index(inplace=True, drop=False)\n",
    "    R_df['Index'] = R_df.index\n",
    "    R_df.set_index('Round Status', inplace=True)\n",
    "    \n",
    "    return R_df['Index']\n",
    "\n",
    "Records['Index'] = Records.groupby(level=[0]).apply(indexer)\n",
    "\n",
    "Records = Records[['Index', 'Date Assigned', 'Date Status']]\n",
    "\n",
    "dept_dict = Permits[['Record Type','Permit #']].drop_duplicates().set_index('Permit #')['Record Type'].to_dict()\n",
    "\n",
    "r = Records.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T18:32:16.968635Z",
     "start_time": "2021-04-23T18:32:01.336081Z"
    },
    "code_folding": [
     2,
     12,
     19,
     122,
     134
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Records = r.copy()\n",
    "\n",
    "sum_cols = [\n",
    "        'Total Days', \n",
    "        'Working Days', \n",
    "        'Rounds', \n",
    "        'Days till Routing', \n",
    "        'Days per Round', \n",
    "        'Submittal Date', \n",
    "        'Complete Date'\n",
    "    ]\n",
    "\n",
    "def sum_days(strt, nd, busi=True):\n",
    "    if busi == True:\n",
    "        days = [d for d in pd.bdate_range(start=strt, end=nd).to_list() if d not in holidays]\n",
    "    if busi == False:\n",
    "        days = pd.date_range(start=strt, end=nd).to_list()\n",
    "    return days\n",
    "\n",
    "def check_days(srt, ned, a_list, t_list):\n",
    "    s = [ss for ss in sum_days(srt, ned, busi=True) if ss not in t_list]\n",
    "    t_list.update(s)\n",
    "    a_list.append(len(s))\n",
    "    return a_list, t_list\n",
    "\n",
    "def round_check(test_df, test, dept):\n",
    "    index = 'Index'\n",
    "    \n",
    "    \n",
    "    \n",
    "    if len(np.where(test[:,0] == 'End')[0]) > 1:\n",
    "        while len(np.where(test[:,0] == 'End')[0]) > 1:\n",
    "            false_end = np.where(test[:,0] == 'End')[0][-1]\n",
    "            test = np.delete(test, false_end, 0)\n",
    "    elif len(np.where(test[:,0] == 'End')[0]) == 0:\n",
    "        test[-1,0] = 'End'\n",
    "\n",
    "    if (len(test) == 1) and (len(test) != len(test_df)): \n",
    "        if test[0,1] > 0:\n",
    "            start_date = pd.to_datetime(test_df.loc[test_df[index] == 0, 'Date Assigned'].values[0])\n",
    "            route_date = pd.to_datetime(test_df.loc[test_df[index] == 0, 'Date Status'].values[0])\n",
    "            test = np.vstack([np.array(['Start', 0, start_date, route_date]), test])\n",
    "            n = True\n",
    "    else:\n",
    "        n = False\n",
    "    round_check = {\n",
    "        'Start':1,\n",
    "        'Round_Start':1,\n",
    "        'Round_End':0,\n",
    "        'End':0\n",
    "    }\n",
    "    \n",
    "    end_gap = False\n",
    "    if (dept != 'Building'):\n",
    "        if(test[-1,0] == 'End')&(len(test[:,0])>1):\n",
    "            if(test[-2,0] == 'Round_End'):\n",
    "                end_gap = True\n",
    "                \n",
    "    check = [round_check[l] for l in list(test[:,0])]\n",
    "\n",
    "    f = 0\n",
    "    for e,c in enumerate(check):\n",
    "        if e == 0:\n",
    "            if (c == 0)&(len(check)>1):\n",
    "                test = np.insert(test, e + f, np.array(('temp_start', \n",
    "                                                            test[e+f,1], \n",
    "                                                            test[e+f,2], \n",
    "                                                            test[e+f,2])), \n",
    "                                     0)  \n",
    "                f += 1\n",
    "            pass\n",
    "        else:\n",
    "            if c != cc:\n",
    "                pass\n",
    "            elif c == cc:\n",
    "                if c == 0:\n",
    "                    test = np.insert(test, e + f, np.array(('temp_start', \n",
    "                                                            test[e+f,1], \n",
    "                                                            test[e+f,2], \n",
    "                                                            test[e+f,2])), \n",
    "                                     0)  \n",
    "                    f += 1\n",
    "                elif (c == 1)and(n==False):\n",
    "                    #try:\n",
    "                    pindex = test[e+f,1]\n",
    "                    #except:\n",
    "                    #    print(false_index)\n",
    "                    if (pindex > 2)&(pindex-2 != test[e+f-1,1]): \n",
    "                        false_index = pindex-2\n",
    "                    else:\n",
    "                        false_index = pindex-1\n",
    "                    try:\n",
    "                        false_date = pd.to_datetime(test_df.loc[test_df[index] == false_index, 'Date Status'].values[0])\n",
    "                    except:\n",
    "                        print(index, test)\n",
    "                        print(test_df.loc[test_df[index] == index, 'Date Status'])\n",
    "                        break\n",
    "                    test = np.insert(test, e + f, np.array(('temp_end', \n",
    "                                                                false_index, \n",
    "                                                                false_date, \n",
    "                                                                false_date)), \n",
    "                                         0)\n",
    "                    #except Exception as exc:\n",
    "                    #    print(false_index, index, e)\n",
    "                    #    logger.error(str(exc))\n",
    "\n",
    "                    f += 1\n",
    "        ee = e\n",
    "        cc = c\n",
    "    if (ee > 0) & (cc == 1):\n",
    "        pindex = test[-1,1]\n",
    "        false_index = pindex\n",
    "        mx = test_df[index].max()-1\n",
    "        if mx == pindex:\n",
    "            mx = test_df[index].max()\n",
    "        false_date = pd.to_datetime(test_df.loc[test_df[index] == mx, 'Date Status'].values[0])\n",
    "        test = np.insert(test, len(test), np.array(('temp_end', \n",
    "                                                false_index, \n",
    "                                                false_date, \n",
    "                                                false_date)), \n",
    "                         0)  \n",
    "    return test[:,2:], end_gap\n",
    "\n",
    "def find_round_length(array, startindex):\n",
    "\n",
    "    if len(array) > 1:\n",
    "        endindex = startindex + 1\n",
    "    else:\n",
    "        endindex = startindex\n",
    "\n",
    "    startdate = array[startindex]\n",
    "    enddate = array[endindex]\n",
    "    round_length = len(sum_days(startdate, enddate, busi=True))\n",
    "    return round_length\n",
    "\n",
    "def describe_rounds(rounds_arr, double_end_problem=False):\n",
    "    SUBMITTAL_DATE = rounds_arr[0][0]\n",
    "    ROUTING_DATE = rounds_arr[0][1]\n",
    "    if (pd.isna(SUBMITTAL_DATE))or(pd.isnull(SUBMITTAL_DATE)):\n",
    "        SUBMITTAL_DATE = ROUTING_DATE\n",
    "        print('first blank')\n",
    "    if (SUBMITTAL_DATE > ROUTING_DATE):\n",
    "        SUBMITTAL_DATE = ROUTING_DATE \n",
    "    if (pd.isna(SUBMITTAL_DATE))or(pd.isnull(SUBMITTAL_DATE)):\n",
    "        SUBMITTAL_DATE = rounds_arr[1][1]\n",
    "        print('second blank')\n",
    "    END_DATE = rounds_arr[-1][1]\n",
    "        \n",
    "    \n",
    "    DAYS_TILL_ROUTING = len(sum_days(SUBMITTAL_DATE, ROUTING_DATE, busi=True))-1\n",
    "    TOTAL_DAYS = len(sum_days(SUBMITTAL_DATE, END_DATE, busi=False))\n",
    "\n",
    "    updates = rounds_arr[:,1]\n",
    "\n",
    "    if ((len(updates) % 2) != 0)and(len(updates)>1):\n",
    "        print('not even', len(updates))\n",
    "        \n",
    "    DAYS_PER_ROUND = [find_round_length(updates, i) for i in range(0,len(updates), 2)]\n",
    "\n",
    "    if double_end_problem == True:\n",
    "        del DAYS_PER_ROUND[-1]\n",
    "    \n",
    "    ROUNDS_COUNT = len(DAYS_PER_ROUND)\n",
    "\n",
    "    PROCESSING_DAYS = sum(DAYS_PER_ROUND)\n",
    "    \n",
    "    return [TOTAL_DAYS, PROCESSING_DAYS, ROUNDS_COUNT, DAYS_TILL_ROUTING, DAYS_PER_ROUND, SUBMITTAL_DATE, END_DATE], rounds_arr[:,1]\n",
    "\n",
    "def RoundLengths(R_df):\n",
    "    \n",
    "    R_df = R_df.reset_index()\n",
    "    \n",
    "    record_id = R_df['Permit #'].values[0]\n",
    "    dept = dept_dict[record_id]\n",
    "    \n",
    "    R_array = R_df[~R_df['Round Status'].isna()][['Round Status', 'Index', 'Date Assigned', 'Date Status']].copy().values\n",
    "    if len(R_array)==0:\n",
    "        R_array = R_df.loc[R_df['Index']==0, ['Round Status', 'Index', 'Date Assigned', 'Date Status']].copy().values\n",
    "    \n",
    "    RoundLength_array, end_check = round_check(R_df, R_array, dept)\n",
    "    \n",
    "    double_end_problem = False\n",
    "    if (end_check == True)and(dept == 'Site Development Permit'):\n",
    "        double_end_problem = True\n",
    "\n",
    "    described_list, rounds = describe_rounds(RoundLength_array, double_end_problem=double_end_problem)\n",
    "\n",
    "    new_row = described_list\n",
    "    \n",
    "    return new_row\n",
    "\n",
    "\n",
    "Sums = Records.groupby(level=[0]).apply(RoundLengths).apply(lambda x:pd.Series(x))\n",
    "Sums.columns = sum_cols\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T18:32:17.031096Z",
     "start_time": "2021-04-23T18:32:16.968635Z"
    }
   },
   "outputs": [],
   "source": [
    "Final_Permits = Admin.join(Sums)\n",
    "for d in [col for col in list(Final_Permits) if 'Date' in col]:\n",
    "    Final_Permits[d.replace('Date','Quarter')] = Final_Permits[d].dt.to_period(\"Q\")\n",
    "    Final_Permits[d.replace('Date','Month')] = Final_Permits[d].dt.to_period('M')\n",
    "    \n",
    "Final_Permits['Rounds & OTC'] = Final_Permits['Rounds'].copy()\n",
    "Final_Permits['Over-the-Counter'] = False\n",
    "\n",
    "Final_Permits.loc[(Final_Permits['Rounds']>1), 'Rounds & OTC'] = Final_Permits.loc[(Final_Permits['Rounds']>1), 'Rounds'].apply(lambda s: str(s) + ' Rounds')\n",
    "Final_Permits.loc[(Final_Permits['Rounds']>4), 'Rounds & OTC'] = '5+ Rounds'\n",
    "Final_Permits.loc[(Final_Permits['Rounds']<=1), 'Rounds & OTC'] = '1 Round'\n",
    "Final_Permits.loc[(Final_Permits['Total Days']<=1), 'Rounds & OTC'] = 'Over-the-Counter'\n",
    "\n",
    "Final_Permits.loc[(Final_Permits['Total Days']<=1), 'Over-the-Counter'] = True\n",
    "\n",
    "Final_Permits[Final_Permits['Rounds']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T00:17:39.651439Z",
     "start_time": "2021-04-23T00:17:39.645443Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Export Excel Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T23:16:42.775812Z",
     "start_time": "2021-04-22T23:16:42.770825Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T18:32:30.421080Z",
     "start_time": "2021-04-23T18:32:26.301969Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def colnum_string(n):\n",
    "    string = \"\"\n",
    "    n = n + 1\n",
    "    while n > 0:\n",
    "        n, remainder = divmod(n - 1, 26)\n",
    "        string = chr(65 + remainder) + string\n",
    "    return string\n",
    "\n",
    "def rng_create(A, one, B, two):\n",
    "    return str(colnum_string(A)) + str(one) + \":\" + str(colnum_string(B)) + str(two)\n",
    "\n",
    "def get_col_widths(dataframe):\n",
    "    # First we find the maximum length of the index column   \n",
    "    idx_max = max([len(str(s)) for s in dataframe.index.values] + [len(str(dataframe.index.name))])\n",
    "    # Then, we concatenate this to the max of the lengths of column name and its values for each column, left to right\n",
    "    return [idx_max] + [max([len(str(s)) for s in dataframe[col].values] + [len(col)]) for col in dataframe.columns]\n",
    "\n",
    "def normalize_types(lyr):\n",
    "        str_list = list(lyr.select_dtypes(include=['datetime','period[Q-DEC]','O']))\n",
    "        convert_dict = {s:str for s in str_list}\n",
    "        no_str = [l for l in list(lyr) if l not in str_list]\n",
    "        no_dict = lyr[no_str].dtypes.to_dict()\n",
    "        convert_dict.update(no_dict)\n",
    "        return lyr.astype(convert_dict)\n",
    "\n",
    "new_path = 'CDD_Permits.xlsx'\n",
    "\n",
    "import xlsxwriter as xlsx\n",
    "wrkbk = xlsx.Workbook(new_path)\n",
    "for OG, name in [(Final_Permits.fillna(value=''),'CDD_Permits')\n",
    "                ]:\n",
    "    worksheet = wrkbk.add_worksheet(name)\n",
    "    \n",
    "    lyr = OG.copy()\n",
    "    \n",
    "    lyr = normalize_types(lyr)\n",
    "    \n",
    "    lyr = lyr.fillna(value='')\n",
    "    \n",
    "    header = np.array([[lyr.index.name] + list(lyr)])\n",
    "    data = lyr.reset_index().to_numpy()\n",
    "    if data.shape[1] != header.shape[1]:        \n",
    "        dif = data.shape[1] - header.shape[1]\n",
    "        fix_head = [lyr.index.name] + list(lyr)\n",
    "        for r in range(dif):\n",
    "            fix_head = [' '] + fix_head\n",
    "        header = np.array([fix_head])\n",
    "    table = np.vstack((header,data))\n",
    "    numRows,numColumns = table.shape\n",
    "    \n",
    "    idx = [0]\n",
    "    if type(lyr.index) == pd.MultiIndex:\n",
    "        idx.append(1)\n",
    "        table[0,0:2] = list(lyr.index.names)\n",
    "    else:\n",
    "        table[0,0:1] = list(lyr.index.names)\n",
    "\n",
    "    for c in range(numColumns):\n",
    "        try:\n",
    "            for r in range(numRows):\n",
    "                format_dict = {'font_name':'Arial'}\n",
    "\n",
    "                # TOP\n",
    "                if (r == 0) & (c not in idx):\n",
    "                    format_dict['bottom'] = 2\n",
    "                    format_dict['bold'] = True\n",
    "                    format_dict['text_wrap'] = True\n",
    "                # INDEX NAME\n",
    "                if (r == 0) & (c in idx):\n",
    "                    format_dict['italic'] = True\n",
    "                # RIGHT\n",
    "                elif (r != 0) & (c == range(numColumns)[-1]):\n",
    "                    format_dict['right'] = 2\n",
    "                    if (r == range(numRows)[-1]):\n",
    "                        format_dict['bottom'] = 2\n",
    "                # LEFT\n",
    "                elif (r != 0) & (c in idx):\n",
    "                    format_dict['bold'] = True\n",
    "                    if (1 not in idx)or(c == 1):\n",
    "                        format_dict['right'] = 2\n",
    "                # BOTTOM\n",
    "                elif (r == range(numRows)[-1]) & (c not in idx):\n",
    "                    format_dict['bottom'] = 2\n",
    "                    if (c == range(numColumns)[-1]):\n",
    "                        format_dict['right'] = 2\n",
    "                item = table[r][c]\n",
    "                if item == np.nan:\n",
    "                    item = ''\n",
    "\n",
    "                cell_format = wrkbk.add_format(format_dict)\n",
    "                worksheet.write(r, c, item, cell_format)\n",
    "            if c not in idx:\n",
    "                worksheet.set_column(c, c, 10)\n",
    "            else:\n",
    "                worksheet.set_column(c, c, len(max(table[:,c], key=len))+1)\n",
    "        except:\n",
    "            print(table[r,c])\n",
    "            \n",
    "    worksheet.add_table('{}:{}'.format(colnum_string(0)+str(1),colnum_string(numColumns-1)+str(numRows)),\n",
    "                       {'columns':[{'header':c} for c in header[0]]})\n",
    "            \n",
    "wrkbk.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
